{
    "name": "root",
    "gauges": {
        "FightAgent.Policy.Entropy.mean": {
            "value": 3.668438673019409,
            "min": 3.5525474548339844,
            "max": 3.9630863666534424,
            "count": 708
        },
        "FightAgent.Policy.Entropy.sum": {
            "value": 75364.40625,
            "min": 59270.171875,
            "max": 89071.59375,
            "count": 708
        },
        "FightAgent.Environment.EpisodeLength.mean": {
            "value": 84.09565217391304,
            "min": 59.02040816326531,
            "max": 217.14583333333334,
            "count": 708
        },
        "FightAgent.Environment.EpisodeLength.sum": {
            "value": 19342.0,
            "min": 13064.0,
            "max": 25409.0,
            "count": 708
        },
        "FightAgent.Self-play.ELO.mean": {
            "value": 519.9387358424665,
            "min": 504.93984031993443,
            "max": 732.2058610786213,
            "count": 708
        },
        "FightAgent.Self-play.ELO.sum": {
            "value": 51993.87358424665,
            "min": 24561.60755109612,
            "max": 117629.53949732342,
            "count": 708
        },
        "FightAgent.Step.mean": {
            "value": 39129991.0,
            "min": 32059905.0,
            "max": 39129991.0,
            "count": 708
        },
        "FightAgent.Step.sum": {
            "value": 39129991.0,
            "min": 32059905.0,
            "max": 39129991.0,
            "count": 708
        },
        "FightAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -53.394073486328125,
            "min": -58.59645462036133,
            "max": -19.813190460205078,
            "count": 708
        },
        "FightAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -7635.3525390625,
            "min": -9188.8369140625,
            "max": -2298.330078125,
            "count": 708
        },
        "FightAgent.Environment.CumulativeReward.mean": {
            "value": -87.29099932312965,
            "min": -249.17317074101146,
            "max": -29.72060587008794,
            "count": 708
        },
        "FightAgent.Environment.CumulativeReward.sum": {
            "value": -8729.099932312965,
            "min": -12558.000032663345,
            "max": -3321.600009381771,
            "count": 708
        },
        "FightAgent.Policy.ExtrinsicReward.mean": {
            "value": -87.29099932312965,
            "min": -249.17317074101146,
            "max": -29.72060587008794,
            "count": 708
        },
        "FightAgent.Policy.ExtrinsicReward.sum": {
            "value": -8729.099932312965,
            "min": -12558.000032663345,
            "max": -3321.600009381771,
            "count": 708
        },
        "FightAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 708
        },
        "FightAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 708
        },
        "FightAgent.Losses.PolicyLoss.mean": {
            "value": 0.01368057545623742,
            "min": 0.01211242172634229,
            "max": 0.022920818767743184,
            "count": 344
        },
        "FightAgent.Losses.PolicyLoss.sum": {
            "value": 0.01368057545623742,
            "min": 0.01211242172634229,
            "max": 0.022920818767743184,
            "count": 344
        },
        "FightAgent.Losses.ValueLoss.mean": {
            "value": 171.66512268066407,
            "min": 39.63694900512695,
            "max": 276.62907165527344,
            "count": 344
        },
        "FightAgent.Losses.ValueLoss.sum": {
            "value": 171.66512268066407,
            "min": 39.63694900512695,
            "max": 276.62907165527344,
            "count": 344
        },
        "FightAgent.Policy.LearningRate.mean": {
            "value": 0.00029765286738237776,
            "min": 0.00029765286738237776,
            "max": 0.00029807559052147,
            "count": 344
        },
        "FightAgent.Policy.LearningRate.sum": {
            "value": 0.00029765286738237776,
            "min": 0.00029765286738237776,
            "max": 0.00029807559052147,
            "count": 344
        },
        "FightAgent.Policy.Epsilon.mean": {
            "value": 0.19921762220000003,
            "min": 0.19921762220000003,
            "max": 0.19935852995999997,
            "count": 344
        },
        "FightAgent.Policy.Epsilon.sum": {
            "value": 0.19921762220000003,
            "min": 0.19921762220000003,
            "max": 0.19935852995999997,
            "count": 344
        },
        "FightAgent.Policy.Beta.mean": {
            "value": 0.004960959347780001,
            "min": 0.004960959347780001,
            "max": 0.004967990645004,
            "count": 344
        },
        "FightAgent.Policy.Beta.sum": {
            "value": 0.004960959347780001,
            "min": 0.004960959347780001,
            "max": 0.004967990645004,
            "count": 344
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1693750080",
        "python_version": "3.8.17 (default, Jul  5 2023, 20:44:21) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "E:\\Anaconda\\Logiciel\\envs\\ml-agents-2.0.1\\Scripts\\mlagents-learn ./trainer_config_new.yaml --run-id SelfPlay --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.0.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1693760952"
    },
    "total": 10871.533286200001,
    "count": 1,
    "self": 0.006918800001585623,
    "children": {
        "run_training.setup": {
            "total": 0.0894619000000001,
            "count": 1,
            "self": 0.0894619000000001
        },
        "TrainerController.start_learning": {
            "total": 10871.4369055,
            "count": 1,
            "self": 10.325924699585812,
            "children": {
                "TrainerController._reset_env": {
                    "total": 5.243124900000922,
                    "count": 16,
                    "self": 5.243124900000922
                },
                "TrainerController.advance": {
                    "total": 10855.764605800416,
                    "count": 539698,
                    "self": 4.901136400532778,
                    "children": {
                        "env_step": {
                            "total": 10850.863469399883,
                            "count": 539698,
                            "self": 8426.193194399477,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 2419.0694213998427,
                                    "count": 539699,
                                    "self": 40.12383519939567,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 2378.945586200447,
                                            "count": 886452,
                                            "self": 2378.945586200447
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 5.600853600564037,
                                    "count": 539697,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 10841.226183100853,
                                            "count": 539697,
                                            "is_parallel": true,
                                            "self": 6329.230875000678,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.01899260000349212,
                                                    "count": 34,
                                                    "is_parallel": true,
                                                    "self": 0.0049445000109971105,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.014048099992495011,
                                                            "count": 204,
                                                            "is_parallel": true,
                                                            "self": 0.014048099992495011
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 4511.976315500171,
                                                    "count": 539697,
                                                    "is_parallel": true,
                                                    "self": 166.1945082991233,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 172.09758950036658,
                                                            "count": 539697,
                                                            "is_parallel": true,
                                                            "self": 172.09758950036658
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3640.9539219003304,
                                                            "count": 539697,
                                                            "is_parallel": true,
                                                            "self": 3640.9539219003304
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 532.7302958003504,
                                                            "count": 1079390,
                                                            "is_parallel": true,
                                                            "self": 146.83495759989376,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 385.89533820045665,
                                                                    "count": 6476340,
                                                                    "is_parallel": true,
                                                                    "self": 385.89533820045665
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 4.979999903298449e-05,
                    "count": 1,
                    "self": 4.979999903298449e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 10861.145933700502,
                                    "count": 511441,
                                    "is_parallel": true,
                                    "self": 73.26304070100014,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 6740.052223599501,
                                            "count": 511441,
                                            "is_parallel": true,
                                            "self": 6738.499812599504,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 1.5524109999964821,
                                                    "count": 14,
                                                    "is_parallel": true,
                                                    "self": 1.5524109999964821
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 4047.8306694000007,
                                            "count": 344,
                                            "is_parallel": true,
                                            "self": 1788.7331153000619,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 2259.097554099939,
                                                    "count": 17200,
                                                    "is_parallel": true,
                                                    "self": 2259.097554099939
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.10320030000002589,
                    "count": 1,
                    "self": 0.005357399999411427,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.09784290000061446,
                            "count": 1,
                            "self": 0.09784290000061446
                        }
                    }
                }
            }
        }
    }
}